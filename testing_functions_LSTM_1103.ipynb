{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "df_female = pd.read_csv('test_data2/df_female.csv')\n",
    "df_age = pd.read_csv('test_data2/df_age.csv')\n",
    "df_SFI = pd.read_csv('test_data2/df_SFI.csv')\n",
    "df_uti = pd.read_csv('test_data2/df_uti.csv')\n",
    "df_admissions = pd.read_csv('test_data2/df_admissions.csv')\n",
    "df_FIM_total = pd.read_csv('test_data2/df_FIM_total.csv')\n",
    "df_acute_days = pd.read_csv('test_data2/df_acute_days.csv')\n",
    "df_brain_injury = pd.read_csv('test_data2/df_brain_injury_mod.csv')\n",
    "\n",
    "#Removing extra column\n",
    "df_female = df_female.loc[:, ~df_female.columns.str.contains('^Unnamed')]\n",
    "df_age = df_age.loc[:, ~df_age.columns.str.contains('^Unnamed')]\n",
    "df_SFI = df_SFI.loc[:, ~df_SFI.columns.str.contains('^Unnamed')]\n",
    "df_uti = df_uti.loc[:, ~df_uti.columns.str.contains('^Unnamed')]\n",
    "df_admissions = df_admissions.loc[:, ~df_admissions.columns.str.contains('^Unnamed')]\n",
    "df_FIM_total = df_FIM_total.loc[:, ~df_FIM_total.columns.str.contains('^Unnamed')]\n",
    "df_acute_days = df_acute_days.loc[:, ~df_acute_days.columns.str.contains('^Unnamed')]\n",
    "df_brain_injury = df_brain_injury.loc[:, ~df_brain_injury.columns.str.contains('^Unnamed')]\n",
    "\n",
    "\n",
    "#rename FIM_total to value (column-name needs to be value for timeseriesflattener)\n",
    "df_FIM_total = df_FIM_total.rename(columns= {'FIM_total': 'value'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  value\n",
      "0        1436    1.0\n",
      "1        2056    0.0\n",
      "2        2492    1.0\n",
      "3        3084    0.0\n",
      "4        3087    0.0\n",
      "...       ...    ...\n",
      "1859  8169844    0.0\n",
      "1860  8267752    1.0\n",
      "1861  8769379    0.0\n",
      "1862  8814557    0.0\n",
      "1863  8869412    0.0\n",
      "\n",
      "[1864 rows x 2 columns]\n",
      "           ID  value        date\n",
      "0        1436      1  2020-08-10\n",
      "1        2056      0         NaN\n",
      "2        2492      1  2019-02-04\n",
      "3        3084      0         NaN\n",
      "4        3087      0         NaN\n",
      "...       ...    ...         ...\n",
      "1859  8169844      0         NaN\n",
      "1860  8267752      1  2020-12-09\n",
      "1861  8769379      0         NaN\n",
      "1862  8814557      0         NaN\n",
      "1863  8869412      0         NaN\n",
      "\n",
      "[1864 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Creating uti df with negative cases as well\n",
    "merged = pd.merge(df_age, df_uti, on=['ID'], how='left')\n",
    "\n",
    "merged = merged[['ID','value']]\n",
    "\n",
    "#turning UVI-neg cases from nan to 0\n",
    "where_are_NaNs = np.isnan(merged)\n",
    "merged[where_are_NaNs] = 0\n",
    "\n",
    "#checking\n",
    "print(merged)\n",
    "\n",
    "#Changing from floats to int\n",
    "merged['value'] = merged['value'].astype('int')\n",
    "\n",
    "merged = pd.merge(merged, df_uti, on=['ID', 'value'], how='left')\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of: 1864 patients, 1373 have fewer than 100 notes. That is 73% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1373"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just a test of how many patients have how X notes\n",
    "\n",
    "few = 100\n",
    "i=0\n",
    "k=0\n",
    "\n",
    "for ID in df_SFI['ID'].unique():\n",
    "    k += 1\n",
    "    df_SFI_sub = df_SFI[df_SFI['ID'] == ID]\n",
    "    if len(df_SFI_sub) < few:\n",
    "        i += 1\n",
    "        #print(len(df_tfidfvect_train_sub))\n",
    "\n",
    "print(f\"Out of: {k} patients, {i} have fewer than {few} notes. That is {int(i/k*100)}% \")\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3377919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4361311</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4458004</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4384550</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008712</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>4954644</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>6076316</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>6326651</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>6621963</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>7061967</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  value\n",
       "0     3377919    NaN\n",
       "1     4361311    9.0\n",
       "2     4458004   39.0\n",
       "3     4384550   50.0\n",
       "4     5008712   12.0\n",
       "...       ...    ...\n",
       "1859  4954644   33.0\n",
       "1860  6076316   53.0\n",
       "1861  6326651   82.0\n",
       "1862  6621963   28.0\n",
       "1863  7061967   35.0\n",
       "\n",
       "[1864 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_age = df_age.rename(columns= {'age': 'value'})\n",
    "df_female = df_female.rename(columns= {'sex': 'value'})\n",
    "df_acute_days = df_acute_days.rename(columns= {' acute_days': 'value'})\n",
    "\n",
    "\n",
    "df_acute_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important to call predictors static, dynamic or text, otherwise they will be skipped because the function will not know how to handle them!\n",
    "#Make a disclaimer message if there is such a df in the predictor dict\n",
    "predictor_dict = {'df_SFI_text':df_SFI, 'df_age_static':df_age, 'df_female_static':df_female, 'df_acute_days_static':df_acute_days, 'df_FIM_total_dynamic':df_FIM_total }#, 'df_brain_injury_static':df_brain_injury}  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in trainingset:362\n",
      "Percentage of positive class in trainingset: 27.76073619631902\n",
      "Number of observations in testset:156\n",
      "Percentage of positive class in testset: 27.857142857142858\n"
     ]
    }
   ],
   "source": [
    "predictor_dict_train, predictor_dict_test, y_train_df, y_test_df, df_admissions_train, df_admissions_test = preprocessing.data_split(df_outcome = merged, predictor_dict = predictor_dict, df_admissions = df_admissions, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projekter\\RHN\\linapd\\tfidf_hyperparamsearch.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_train_SFI['note'] = X_train_SFI['note'].str.replace('\\d+', '')\n",
      "e:\\Projekter\\RHN\\linapd\\tfidf_hyperparamsearch.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_test_SFI['note'] = X_test_SFI['note'].str.replace('\\d+', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens ['adspurgt' 'aff' 'afføring' 'aftalt' 'aften' 'aftenvagten' 'av' 'bad'\n",
      " 'beder' 'behandling' 'behov' 'besøg' 'ble' 'bleen' 'bleer' 'bleskift'\n",
      " 'blevet' 'blod' 'blære' 'blæren' 'blærescannet' 'brugt' 'bukseble'\n",
      " 'bukser' 'bundskift' 'bundskiftet' 'bækken' 'bækkenstol' 'ca' 'dag' 'dd'\n",
      " 'diurese' 'dv' 'efterfølgende' 'ej' 'evt' 'faldet' 'fik' 'fint'\n",
      " 'forbindelse' 'forsøgt' 'fortsat' 'fortæller' 'fungerer' 'fået' 'får'\n",
      " 'føler' 'gang' 'gange' 'gerne' 'giver' 'givet' 'godt' 'grundet' 'gul'\n",
      " 'gå' 'gået' 'går' 'haft' 'held' 'hele' 'helt' 'hjælp' 'hjælpes' 'holde'\n",
      " 'hvil' 'hvilket' 'ifm' 'ildelugtende' 'inden' 'kad' 'kalder' 'kateter'\n",
      " 'kath' 'kl' 'klar' 'kolbe' 'kolben' 'komme' 'kommet' 'konc'\n",
      " 'koncentreret' 'kort' 'lade' 'lang' 'let' 'ligger' 'lys' 'læge' 'løbet'\n",
      " 'ml' 'morgen' 'muligt' 'mængde' 'mærke' 'mærker' 'mørk' 'nat' 'natten'\n",
      " 'nedre' 'nitrit' 'nåede' 'når' 'obs' 'par' 'pga' 'pose' 'posen' 'positiv'\n",
      " 'prøve' 'pt' 'påsat' 'relevant' 'resultat' 'ringer' 'samt' 'sat' 'scan'\n",
      " 'scannet' 'se' 'sendes' 'sendt' 'seng' 'sengen' 'sep' 'seponeret' 'ser'\n",
      " 'siddende' 'sidder' 'sidst' 'sidste' 'siger' 'sik' 'sikket' 'skift'\n",
      " 'skiftes' 'skiftet' 'slangen' 'små' 'spontan' 'stikbækken' 'stix'\n",
      " 'stixet' 'stor' 'store' 'str' 'stuegang' 'stuen' 'står' 'svært' 'tage'\n",
      " 'tages' 'taget' 'tid' 'tilbudt' 'tilbydes' 'tilsyn' 'time' 'tisse'\n",
      " 'tisser' 'tisset' 'to' 'toilet' 'toiletbesøg' 'toiletstol' 'toilettet'\n",
      " 'trang' 'trods' 'tung' 'tøj' 'tømt' 'tør' 'udtryk' 'uheld' 'underbukser'\n",
      " 'uridom' 'uridomet' 'urin' 'urinen' 'urinpose' 'urolig' 'ut' 'uvi'\n",
      " 'vagten' 'vand' 'vandet' 'vandl' 'vandladning' 'vandladninger'\n",
      " 'vandladningstrang' 'vandladningsuheld' 'virker' 'viser' 'vl' 'våd'\n",
      " 'våde' 'vådt' 'væske' 'wc' 'ønsker']\n"
     ]
    }
   ],
   "source": [
    "from tfidf import tf_idf\n",
    "\n",
    "df_tfidfvect_train, df_tfidfvect_test = tf_idf(predictor_dict_train[\"df_SFI_text\"], predictor_dict_test[\"df_SFI_text\"], min_df = 5, max_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_embeddings import sentence_embeddings\n",
    "\n",
    "# df_sentence_train = sentence_embeddings(df_free_text = predictor_dict_train[\"df_SFI_text\"], transformer_model = 'encoder-large-v1')\n",
    "\n",
    "# df_sentence_test = sentence_embeddings(df_free_text = predictor_dict_test[\"df_SFI_text\"], transformer_model = 'encoder-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test a smaller subset\n",
    "\n",
    "ID_list_train  = []\n",
    "[ID_list_train.append(i) for i in df_tfidfvect_train['ID'].unique()]\n",
    "\n",
    "small_ID_list_train = ID_list_train[:100]\n",
    "\n",
    "df_tfidfvect_train_small = df_tfidfvect_train[df_tfidfvect_train['ID'].isin(small_ID_list_train)]\n",
    "df_admissions_train_small = df_admissions_train[df_admissions_train['ID'].isin(small_ID_list_train)]\n",
    "y_train_df_small = y_train_df[y_train_df['ID'].isin(small_ID_list_train)]\n",
    "\n",
    "ID_list_test = []\n",
    "[ID_list_test.append(i) for i in df_tfidfvect_test['ID'].unique()]\n",
    "\n",
    "small_ID_list_test = ID_list_test[:40]\n",
    "\n",
    "df_tfidfvect_test_small = df_tfidfvect_test[df_tfidfvect_test['ID'].isin(small_ID_list_test)]\n",
    "df_admissions_test_small = df_admissions_test[df_admissions_test['ID'].isin(small_ID_list_test)]\n",
    "y_test_df_small = y_test_df[y_test_df['ID'].isin(small_ID_list_test)]\n",
    "\n",
    "## same, but for sentence (the other df's are the same)\n",
    "#df_sentence_train_small = df_sentence_train[df_sentence_train['ID'].isin(small_ID_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "\n",
    "from create_tensors import max_notes, tensors\n",
    "import torch\n",
    "\n",
    "# '''REMEMBER: possible to manually set look_back and look_ahead\n",
    "# Look_back must be set to the same in both max_notes and tensors to create correct padding.\n",
    "# (default look_back = 4, look_ahead = 3)'''\n",
    "\n",
    "\n",
    "# #hvad hvis der er en i testsættet der har flere notes?? skal vel tjekke begge og tage den med flest??\n",
    "# maximum_notes_train = max_notes(df_tfidfvect_train_small, df_admissions_train_small)\n",
    "# print(maximum_notes_train)\n",
    "\n",
    "# maximum_notes_test = max_notes(df_tfidfvect_test_small, df_admissions_test_small)\n",
    "# print(maximum_notes_test)\n",
    "\n",
    "# maximum_notes = max(maximum_notes_train, maximum_notes_test)\n",
    "# print(maximum_notes)\n",
    "maximum_notes = 32\n",
    "\n",
    "#train\n",
    "X_tfidfvect_train_tensor, y_tfidfvect_train_tensor, X_structured_train_tensor_tfidf = tensors(df_tfidfvect_train_small, y_train_df_small, df_admissions_train_small, maximum_notes, predictor_dict_train)\n",
    "torch.save(X_tfidfvect_train_tensor, 'X_tfidfvect_train_tensor_4_days_test.pt')\n",
    "torch.save(y_tfidfvect_train_tensor, 'y_tfidfvect_train_tensor_4_days_test.pt')\n",
    "# torch.save(X_static_train_tensor, 'X_static_train_tensor_4_days_test.pt')\n",
    "# torch.save(X_dynamic_train_tensor, 'X_dynamic_train_tensor_4_days_test.pt')\n",
    "torch.save(X_structured_train_tensor_tfidf, 'X_structured_train_tensor_tfidf_4_days_subset.pt')\n",
    "\n",
    "#test\n",
    "X_tfidfvect_test_tensor, y_tfidfvect_test_tensor, X_structured_test_tensor_tfidf = tensors(df_tfidfvect_test_small, y_test_df_small, df_admissions_test_small, maximum_notes, predictor_dict_test)\n",
    "torch.save(X_tfidfvect_test_tensor, 'X_tfidfvect_test_tensor_4_days_test.pt')\n",
    "torch.save(y_tfidfvect_test_tensor, 'y_tfidfvect_test_tensor_4_days_test.pt')\n",
    "# torch.save(X_static_test_tensor, 'X_static_test_tensor_4_days_test.pt')\n",
    "# torch.save(X_dynamic_test_tensor, 'X_dynamic_test_tensor_4_days_test.pt')\n",
    "torch.save(X_structured_test_tensor_tfidf, 'X_structured_test_tensor_tfidf_4_days_subset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4673, 4])\n",
      "torch.Size([4673, 32, 200])\n",
      "tensor([65.,  0., 26., 21.])\n",
      "tensor([65.,  0., 26., 21.])\n"
     ]
    }
   ],
   "source": [
    "#print(X_static_train_tensor.size())\n",
    "#print(X_dynamic_train_tensor.size())\n",
    "print(X_structured_train_tensor_tfidf.size())\n",
    "print(X_tfidfvect_train_tensor.size())\n",
    "\n",
    "print(X_structured_train_tensor_tfidf[0])\n",
    "print(X_structured_train_tensor_tfidf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from create_tensors import max_notes, tensors\n",
    "# import torch\n",
    "\n",
    "# '''REMEMBER: possible to manually set look_back and look_ahead\n",
    "# Look_back must be set to the same in both max_notes and tensors to create correct padding.\n",
    "# (default look_back = 4, look_ahead = 3)'''\n",
    "\n",
    "# maximum_notes_train = max_notes(df_sentence_train, df_admissions_train)\n",
    "# print(maximum_notes_train)\n",
    "\n",
    "# maximum_notes_test = max_notes(df_sentence_test, df_admissions_test)\n",
    "# print(maximum_notes_test)\n",
    "\n",
    "# maximum_notes = max(maximum_notes_train, maximum_notes_test)\n",
    "# print(maximum_notes)\n",
    "\n",
    "# X_sentence_train_tensor, y_sentence_train_tensor, X_structured_train_tensor_sentence = tensors(df_sentence_train, y_train_df, df_admissions_train, maximum_notes, predictor_dict_train)\n",
    "# torch.save(X_sentence_train_tensor, 'X_sentence_train_tensor_4_days.pt')\n",
    "# torch.save(y_sentence_train_tensor, 'y_sentence_train_tensor_4_days.pt')\n",
    "# torch.save(X_structured_train_tensor_sentence, 'X_structured_train_tensor_sentence_4_days.pt')\n",
    "\n",
    "# X_sentence_test_tensor, y_sentence_test_tensor, X_structured_test_tensor_sentence = tensors(df_sentence_test, y_test_df, df_admissions_test, maximum_notes, predictor_dict_test)\n",
    "# torch.save(X_sentence_test_tensor, 'X_sentence_test_tensor_4_days.pt')\n",
    "# torch.save(y_sentence_test_tensor, 'y_sentence_test_tensor_4_days.pt')\n",
    "# torch.save(X_structured_test_tensor_sentence, 'X_structured_test_tensor_sentence_4_days.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from create_tensors import max_notes, tensors\n",
    "# import torch\n",
    "\n",
    "# '''REMEMBER: possible to manually set look_back and look_ahead\n",
    "# Look_back must be set to the same in both max_notes and tensors to create correct padding.\n",
    "# (default look_back = 4, look_ahead = 3)'''\n",
    "\n",
    "\n",
    "# #hvad hvis der er en i testsættet der har flere notes?? skal vel tjekke begge og tage den med flest??\n",
    "# maximum_notes_train = max_notes(df_tfidfvect_train, df_admissions_train)\n",
    "# print(maximum_notes_train)\n",
    "\n",
    "# maximum_notes_test = max_notes(df_tfidfvect_test, df_admissions_test)\n",
    "# print(maximum_notes_test)\n",
    "\n",
    "# maximum_notes = max(maximum_notes_train, maximum_notes_test)\n",
    "# print(maximum_notes)\n",
    "\n",
    "# #train\n",
    "# X_tfidfvect_train_tensor, y_tfidfvect_train_tensor, X_structured_train_tensor_tfidf = tensors(df_tfidfvect_train, y_train_df, df_admissions_train, maximum_notes, predictor_dict_train)\n",
    "# torch.save(X_tfidfvect_train_tensor, 'X_tfidfvect_train_tensor_4_days.pt')\n",
    "# torch.save(y_tfidfvect_train_tensor, 'y_tfidfvect_train_tensor_4_days.pt')\n",
    "# torch.save(X_structured_train_tensor_tfidf, 'X_structured_train_tensor_tfidf_4_days.pt')\n",
    "\n",
    "# #test\n",
    "# X_tfidfvect_test_tensor, y_tfidfvect_test_tensor, X_structured_test_tensor_tfidf = tensors(df_tfidfvect_test, y_test_df, df_admissions_test, maximum_notes, predictor_dict_test)\n",
    "# torch.save(X_tfidfvect_test_tensor, 'X_tfidfvect_test_tensor_4_days.pt')\n",
    "# torch.save(y_tfidfvect_test_tensor, 'y_tfidfvect_test_tensor_4_days.pt')\n",
    "# torch.save(X_structured_test_tensor_tfidf, 'X_structured_test_tensor_tfidf_4_days.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## KØR HERTIL! ###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING TENSORS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "# '''Sentence'''\n",
    "# #train\n",
    "# X_sentence_train_tensor = torch.load('X_sentence_train_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "# y_sentence_train_tensor = torch.load('y_sentence_train_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "\n",
    "# #test\n",
    "# X_sentence_test_tensor = torch.load('X_sentence_test_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "# y_sentence_test_tensor = torch.load('y_sentence_test_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "\n",
    "# print(X_sentence_train_tensor.size())\n",
    "# print(y_sentence_train_tensor.size())\n",
    "# print(X_sentence_test_tensor.size())\n",
    "# print(y_sentence_test_tensor.size())\n",
    "\n",
    "\n",
    "\n",
    "# # '''Tf-idf'''\n",
    "# # #train\n",
    "# X_tfidfvect_train_tensor = torch.load('X_tfidfvect_train_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "# y_tfidfvect_train_tensor = torch.load('y_stfidfvect_train_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "\n",
    "# #test\n",
    "# X_tfidfvect_test_tensor = torch.load('X_tfidfvect_test_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "# y_tfidfvect_test_tensor = torch.load('y_tfidfvect_test_tensor_4_days.pt', map_location=torch.device('cuda'))\n",
    "\n",
    "# print(X_tfidfvect_train_tensor.size())\n",
    "# print(y_tfidfvect_train_tensor.size())\n",
    "# print(X_tfidfvect_test_tensor.size())\n",
    "# print(y_tfidfvect_test_tensor.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4673, 32, 200])\n",
      "torch.Size([4673])\n",
      "torch.Size([4673, 4])\n",
      "torch.Size([1893, 32, 200])\n",
      "torch.Size([1893])\n",
      "torch.Size([1893, 4])\n"
     ]
    }
   ],
   "source": [
    "'''Tf-idf SUBSETS'''\n",
    "#train\n",
    "X_tfidfvect_train_tensor = torch.load('X_tfidfvect_train_tensor_4_days_subset.pt', map_location=torch.device('cuda'))\n",
    "y_tfidfvect_train_tensor = torch.load('y_tfidfvect_train_tensor_4_days_subset.pt', map_location=torch.device('cuda'))\n",
    "X_structured_train_tensor_tfidf = torch.load('X_structured_train_tensor_tfidf_4_days_subset.pt', map_location=torch.device('cuda'))\n",
    "\n",
    "#test\n",
    "X_tfidfvect_test_tensor = torch.load('X_tfidfvect_test_tensor_4_days_subset.pt', map_location=torch.device('cuda'))\n",
    "y_tfidfvect_test_tensor = torch.load('y_tfidfvect_test_tensor_4_days_subset.pt', map_location=torch.device('cuda'))\n",
    "X_structured_test_tensor_tfidf = torch.load('X_structured_test_tensor_tfidf_4_days_subset.pt', map_location=torch.device('cuda'))\n",
    "\n",
    "\n",
    "print(X_tfidfvect_train_tensor.size())\n",
    "print(y_tfidfvect_train_tensor.size())\n",
    "print(X_structured_train_tensor_tfidf.size())\n",
    "\n",
    "\n",
    "print(X_tfidfvect_test_tensor.size())\n",
    "print(y_tfidfvect_test_tensor.size())\n",
    "print(X_structured_test_tensor_tfidf.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1893, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Gets them to same dimension, but works worse???\n",
    "y_tfidfvect_train_tensor = torch.unsqueeze(y_tfidfvect_train_tensor, 1).cuda()\n",
    "y_tfidfvect_test_tensor = torch.unsqueeze(y_tfidfvect_test_tensor, 1).cuda()\n",
    "\n",
    "y_tfidfvect_test_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(y_tfidfvect_train_tensor.device)\n",
    "print(y_tfidfvect_test_tensor.device)\n",
    "print(X_tfidfvect_train_tensor.device)\n",
    "print(X_tfidfvect_test_tensor.device)\n",
    "print(X_structured_train_tensor_tfidf.device)\n",
    "print(X_structured_test_tensor_tfidf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 #10 epochs\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = 200 #number of features\n",
    "hidden_size = 60 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes \n",
    "seq_length = X_tfidfvect_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA A100-PCIE-40GB\n",
      "168222208\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "#Device ID of the GPU\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "#Device name of the GPU\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "#memory used on GPU\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Testing\n",
    "# from LSTM import LSTM1\n",
    "# my_LSTM = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "\n",
    "# cuda_LSTM = my_LSTM.to(\"cuda\")\n",
    "\n",
    "# for param in cuda_LSTM.parameters():\n",
    "#     print (param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "Epoch: 0, loss: 0.00015\n",
      "Epoch: 2, loss: 0.00019\n",
      "Epoch: 4, loss: 0.00016\n",
      "Epoch: 6, loss: 0.00015\n",
      "Epoch: 8, loss: 0.00014\n"
     ]
    }
   ],
   "source": [
    "from LSTM import LSTM1\n",
    "import torch #pytorch\n",
    "import math\n",
    "from batches import batch\n",
    "\n",
    "#instantiating LSTM1 object\n",
    "my_LSTM = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length).to(\"cuda\")\n",
    "\n",
    "for param in my_LSTM.parameters():\n",
    "    print (param.device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(my_LSTM.parameters(), lr=learning_rate) \n",
    "\n",
    "# print(list(batches_x)[0])\n",
    "# n_batches = sum(1 for _ in batches_x)\n",
    "# print(n_batches)\n",
    "# print(list(batches_x)[0])\n",
    "\n",
    "\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    batch_size = 32\n",
    "    batches_x = batch(X_tfidfvect_train_tensor, batch_size)\n",
    "    batches_y = batch(y_tfidfvect_train_tensor, batch_size)\n",
    "\n",
    "    n_batches = math.ceil(len(X_tfidfvect_train_tensor)/batch_size)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        batch_x = next(batches_x)\n",
    "        for j in batch_x:\n",
    "            batch_x_new = torch.stack(batch_x)\n",
    "        \n",
    "        batch_y = next(batches_y)\n",
    "        for k in batch_y:\n",
    "            batch_y_new = torch.stack(batch_y)\n",
    "\n",
    "        outputs = my_LSTM.forward(batch_x_new)# (X_train_tensor) #forward pass\n",
    "        optimizer.zero_grad() #calculate the gradient, manually setting to 0\n",
    "\n",
    "        #obtaining loss function\n",
    "        loss = criterion(outputs, batch_y_new) \n",
    "\n",
    "        loss.backward() #calculates the loss of the loss function\n",
    "\n",
    "        optimizer.step() #improve from loss, i.e backprop\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "batches_x = batch(X_tfidfvect_test_tensor, batch_size)\n",
    "batches_y = batch(y_tfidfvect_test_tensor, batch_size)\n",
    "\n",
    "n_batches = math.ceil(len(X_tfidfvect_test_tensor)/batch_size)\n",
    "    \n",
    "test_loss = 0.0\n",
    "# Generate predictions for the test dataset\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        batch_x = next(batches_x)\n",
    "        for j in batch_x:\n",
    "            batch_x_new = torch.stack(batch_x)\n",
    "        \n",
    "        batch_y = next(batches_y)\n",
    "        for k in batch_y:\n",
    "            batch_y_new = torch.stack(batch_y)\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = my_LSTM(batch_x_new)\n",
    "\n",
    "        loss = criterion(outputs, batch_y_new)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Save the predictions\n",
    "        predictions += outputs.squeeze().tolist()\n",
    "        \n",
    "\n",
    "    # Compute the evaluation metrics\n",
    "    avg_test_loss = test_loss / len(X_tfidfvect_test_tensor)\n",
    "    print('Average Test Loss: {:.4f}'.format(avg_test_loss))\n",
    "\n",
    "\n",
    "# Convert the predictions and actual values to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "actuals = y_tfidfvect_test_tensor.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)\n",
    "\n",
    "len(y_tfidfvect_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011317039839923382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      1866\n",
      "         1.0       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.99      1893\n",
      "   macro avg       0.49      0.50      0.50      1893\n",
      "weighted avg       0.97      0.99      0.98      1893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\linapd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\ProgramData\\Anaconda3\\envs\\linapd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\ProgramData\\Anaconda3\\envs\\linapd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#[print(i) for i in predictions]\n",
    "\n",
    "#HVORFOR GÆTTER DEN KUN 1???? \n",
    "print(max(np.unique(predictions)))\n",
    "\n",
    "# Applying transformation to get binary values predictions with 0.5 as thresold\n",
    "binary_predictions = list(map(lambda x: 0 if x < 0.5 else 1, predictions))\n",
    "\n",
    "\n",
    "print(classification_report(y_tfidfvect_test_tensor.cpu(), binary_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(f\"True Positives: {TP}. False Positives: {FP}. True negatives: {TN}. False negatives: {FN}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0. False Positives: 0. True negatives: 1866. False negatives: 27.\n"
     ]
    }
   ],
   "source": [
    "print(perf_measure(actuals, binary_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8f971b8dfd9a50933f9f90bf438ea60c1e2a4d59ca31e1c83263c2e44374f38"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('linapd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
