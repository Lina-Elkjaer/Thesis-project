{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uti = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/UTI_pos_1212.csv', delimiter = ';')\n",
    "\n",
    "df_sex = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/sex_0512.csv', delimiter = ';')\n",
    "\n",
    "df_age = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/age_0512.csv', delimiter = ';')\n",
    "\n",
    "df_SFI = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/SFI_urination_0512.csv', delimiter = ';')\n",
    "\n",
    "df_acute_days = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/acute_days_0512.csv', delimiter = ';')\n",
    "\n",
    "df_FIM_total = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/FIM_total_0512.csv', delimiter = ';')\n",
    "\n",
    "df_brain_injury_mod = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/brain_injury_modified_0512.csv', delimiter = ';')\n",
    "\n",
    "\n",
    "df_SFI_psyk = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/SFI_psykosocial_group_0512.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apopleksi' 'Traumatisk' 'SAH' 'Ingen' 'Infektioner' 'Encephalopati'\n",
      " 'Bl√∏dning' 'Fejl' 'Tumor' 'Andet' 'Funktionel lidelse' 'Ukendt']\n"
     ]
    }
   ],
   "source": [
    "print(df_brain_injury_mod['injury_modified'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FIM_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking that it worked\n",
    "print(len(df_sex['ID'].unique()))\n",
    "print(len(df_sex))\n",
    "print(len(df_age))\n",
    "print(len(df_uti))\n",
    "print(len(df_brain_injury_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kvinde' 'Mand' nan]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(df_sex['sex'].unique())\n",
    "\n",
    "df_sex = df_sex[df_sex['sex'].isin(['Kvinde', 'Mand'])]\n",
    "\n",
    "#Replacing strings with 1 and 0 and rename df\n",
    "df_female = df_sex.replace('Kvinde', 1)\n",
    "df_female = df_female.replace('Mand', 0)\n",
    "\n",
    "print(df_female['sex'].unique()) #checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5392069]\n",
      "1864\n",
      "133086\n"
     ]
    }
   ],
   "source": [
    "#Printing the ID's of patients with sex == nan\n",
    "print(np.setdiff1d(df_age['ID'],df_female['ID']))\n",
    "\n",
    "\n",
    "#Removing the patient without gender from the other dfs\n",
    "df_age = df_age[df_age['ID'].isin(df_female['ID'])]\n",
    "print(len(df_age)) #test\n",
    "df_SFI = df_SFI[df_SFI['ID'].isin(df_female['ID'])]\n",
    "print(len(df_SFI)) #test\n",
    "df_acute_days = df_acute_days[df_acute_days['ID'].isin(df_female['ID'])]\n",
    "df_FIM_total = df_FIM_total[df_FIM_total['ID'].isin(df_female['ID'])]\n",
    "df_brain_injury_mod = df_brain_injury_mod[df_brain_injury_mod['ID'].isin(df_female['ID'])]\n",
    "\n",
    "\n",
    "df_SFI_psyk = df_SFI_psyk[df_SFI_psyk['ID'].isin(df_female['ID'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SFI\n",
    "\n",
    "#Checking for dublicates, if numbers are the same, there are no dublicates\n",
    "print(len(df_SFI)) #133.086\n",
    "print(len(df_SFI.drop_duplicates()))  #133.086\n",
    "\n",
    "df1 = df_SFI[df_SFI.isna().any(axis=1)]\n",
    "print(df1)\n",
    "\n",
    "df_SFI = df_SFI.dropna()\n",
    "\n",
    "print(len(df_SFI)) #133.085, that is, one empty note was removed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Checking for dublicates, if numbers are the same, there are no dublicates\n",
    "print(len(df_SFI_psyk)) #133.086\n",
    "print(len(df_SFI_psyk.drop_duplicates()))  #133.086\n",
    "\n",
    "df1_psyk = df_SFI_psyk[df_SFI_psyk.isna().any(axis=1)]\n",
    "print(df1_psyk)\n",
    "\n",
    "df_SFI_psyk = df_SFI_psyk.dropna()\n",
    "\n",
    "print(len(df_SFI_psyk)) #133.085, that is, one empty note was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True    133085\n",
      "Name: ID, dtype: int64\n",
      "True     518\n",
      "False    187\n",
      "Name: ID, dtype: int64\n",
      "False    1346\n",
      "True      518\n",
      "Name: ID, dtype: int64\n",
      "True    111864\n",
      "Name: ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Are there any ID's in SFI, not in df_female?\n",
    "print(df_SFI['ID'].isin(df_female['ID']).value_counts())\n",
    "# No\n",
    "\n",
    "#Are there any ID's in UTI, not in df_female?\n",
    "print(df_uti['ID'].isin(df_female['ID']).value_counts())\n",
    "# Yes, 180 (506 are in both). I.e. 180 patients with UTI do not have data in urination SFI, that is a lot, why is this number so large??\n",
    "# Some are < 18\n",
    "\n",
    "#Are there any ID's in df_female, not in UTI?\n",
    "print(df_female['ID'].isin(df_uti['ID']).value_counts())\n",
    "#Yes, 1358, these are all the patients that do not get a UTI\n",
    "\n",
    "#Are there any ID's in SFI, not in df_female?\n",
    "print(df_SFI_psyk['ID'].isin(df_female['ID']).value_counts())\n",
    "# No\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acute_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1864\n",
      "[ 1. nan]\n",
      "[1]\n",
      "518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINLINAPD\\AppData\\Local\\Temp\\11\\ipykernel_4600\\1291876411.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['UTI'] = filtered_df['UTI'].astype('int') #For some reason merge changed the values to floats, therefore I change them back\n"
     ]
    }
   ],
   "source": [
    "#Merging to ensure that we only keep the UTI patients who also have free-text data\n",
    "mergedStuff = pd.merge(df_age, df_uti, on=['ID'], how='left')\n",
    "mergedStuff\n",
    "\n",
    "\n",
    "print(len(mergedStuff['ID'].unique()))\n",
    "\n",
    "print(mergedStuff['UTI'].unique()) #checking what the column contains\n",
    "\n",
    "filtered_df = mergedStuff[mergedStuff['UTI'].notnull()] #deleting UTI neg from the df so I can make a new UTI df \n",
    "#filtered_df = filtered_df.replace(1.0, 1)\n",
    "filtered_df['UTI'] = filtered_df['UTI'].astype('int') #For some reason merge changed the values to floats, therefore I change them back\n",
    "print(filtered_df['UTI'].unique()) #checking that it worked\n",
    "\n",
    "print(len(filtered_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only relevant columns\n",
    "df_uti = filtered_df[['ID', 'UTI', 'date']]\n",
    "\n",
    "df_uti\n",
    "\n",
    "#rename UTI to value (column-name needs to be value for timeseriesflattener)\n",
    "df_uti = df_uti.rename(columns= {'UTI': 'value'})\n",
    "\n",
    "df_uti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions = pd.read_csv('C:/Users/ADMINLINAPD/Documents/data/admissions_0512.csv', delimiter = ';')\n",
    "\n",
    "df_admissions \n",
    "df_admissions['admission_start']= pd.to_datetime(df_admissions['admission_start']).dt.date  #Last bit deletes time of day\n",
    "df_admissions['admission_end']= pd.to_datetime(df_admissions['admission_end']).dt.date\n",
    "df_admissions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create column of all days each patient is admitted, based on admission_start and admission_end \n",
    "df_admissions2 = pd.concat([pd.DataFrame({'date': pd.date_range(row['admission_start'], row['admission_end'], freq='D'), 'ID': row['ID']})\n",
    "           for i, row in df_admissions.iterrows()], ignore_index=True)\n",
    "\n",
    "def first_last(df_admissions2):\n",
    "     return df_admissions2.iloc[1:-1]\n",
    "\n",
    "df_admissions2 = df_admissions2[df_admissions2.duplicated('ID', keep='last')] #removing last day of every group (day of discharge)\n",
    "df_admissions2 = df_admissions2[df_admissions2.duplicated('ID', keep='first')] #removing first day of every group (day of admission)\n",
    "\n",
    "sub = df_admissions2[df_admissions2['ID']== 8769379] #Checking if it worked on a random patient\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the wanted time of prediction \n",
    "df_admissions2['date'] = df_admissions2['date'] + pd.Timedelta(hours=8, minutes=00, seconds=00)\n",
    "df_admissions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Writing csvs of the dfs\n",
    "# df_uti.to_csv(\"test_data2/df_uti.csv\")\n",
    "# df_SFI.to_csv(\"test_data2/df_SFI.csv\")\n",
    "# df_admissions2.to_csv(\"test_data2/df_admissions.csv\")\n",
    "# df_age.to_csv(\"test_data2/df_age.csv\")\n",
    "# df_female.to_csv(\"test_data2/df_female.csv\")\n",
    "# df_FIM_total.to_csv(\"test_data2/df_FIM_total.csv\")\n",
    "# df_acute_days.to_csv(\"test_data2/df_acute_days.csv\")\n",
    "# df_brain_injury_mod.to_csv(\"test_data2/df_brain_injury_mod.csv\")\n",
    "\n",
    "df_SFI_psyk.to_csv(\"test_data2/df_SFI_psyk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional necessary cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#loading data\n",
    "df_female = pd.read_csv('test_data2/df_female.csv', index_col=[0])\n",
    "df_age = pd.read_csv('test_data2/df_age.csv', index_col=[0])\n",
    "df_SFI = pd.read_csv('test_data2/df_SFI.csv', index_col=[0])\n",
    "df_uti = pd.read_csv('test_data2/df_uti.csv', index_col=[0])\n",
    "df_admissions = pd.read_csv('test_data2/df_admissions.csv', index_col=[0])\n",
    "df_FIM_total = pd.read_csv('test_data2/df_FIM_total.csv', index_col=[0])\n",
    "df_acute_days = pd.read_csv('test_data2/df_acute_days.csv', index_col=[0])\n",
    "df_brain_injury = pd.read_csv('test_data2/df_brain_injury_mod.csv', index_col=[0])\n",
    "\n",
    "\n",
    "#rename FIM_total to value (column-name needs to be value for timeseriesflattener)\n",
    "df_FIM_total = df_FIM_total.rename(columns= {'FIM_total': 'value'})\n",
    "\n",
    "\n",
    "#Loading resampled data and removing extra column\n",
    "df_SFI_resampled = pd.read_csv('test_data2/df_SFI_resampled.csv', index_col=[0])\n",
    "df_admissions_resampled = pd.read_csv('test_data2/df_prediction_times_resampled.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating uti df with negative cases as well\n",
    "merged = pd.merge(df_age, df_uti, on=['ID'], how='left')\n",
    "\n",
    "merged = merged[['ID','value']]\n",
    "\n",
    "#turning UVI-neg cases from nan to 0\n",
    "where_are_NaNs = np.isnan(merged)\n",
    "merged[where_are_NaNs] = 0\n",
    "\n",
    "#checking\n",
    "#print(merged)\n",
    "\n",
    "#Changing from floats to int\n",
    "merged['value'] = merged['value'].astype('int')\n",
    "\n",
    "df_outcome = pd.merge(merged, df_uti, on=['ID', 'value'], how='left')\n",
    "\n",
    "#print(df_outcome)\n",
    "\n",
    "\n",
    "#Need a little preprocessing for FIM scores to be available for all dates in the admission. Always using the latest available FIM score for each patient\n",
    "df_admissions_without_time = df_admissions.copy() \n",
    "df_admissions_without_time['date'] = pd.to_datetime(df_admissions_without_time['date']).dt.date\n",
    "df_FIM_total['date'] = pd.to_datetime(df_FIM_total['date']).dt.date\n",
    "\n",
    "df_merge = pd.merge(df_admissions_without_time, df_FIM_total, on=['ID', 'date'], how='left')\n",
    "\n",
    "df_merge_filled = df_merge.copy() \n",
    "df_merge_filled.update(df_merge_filled.sort_values([\"ID\", \"date\"]).groupby(\"ID\").ffill()) \n",
    "\n",
    "df_FIM_total = df_merge_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#including only the patients that are in the resampled df \n",
    "patients = df_SFI_resampled['ID'].unique()\n",
    "\n",
    "df_female = df_female.loc[df_female['ID'].isin(patients)]\n",
    "df_age = df_age.loc[df_age['ID'].isin(patients)]\n",
    "df_uti = df_uti.loc[df_uti['ID'].isin(patients)]\n",
    "df_admissions = df_admissions.loc[df_admissions['ID'].isin(patients)]\n",
    "df_FIM_total = df_FIM_total.loc[df_FIM_total['ID'].isin(patients)]\n",
    "df_acute_days = df_acute_days.loc[df_acute_days['ID'].isin(patients)]\n",
    "df_brain_injury = df_brain_injury.loc[df_brain_injury['ID'].isin(patients)]\n",
    "df_outcome= df_outcome.loc[df_outcome['ID'].isin(patients)]\n",
    "df_SFI=df_SFI.loc[df_SFI['ID'].isin(patients)]\n",
    "\n",
    "df_admissions_resampled = df_admissions_resampled.loc[df_admissions_resampled['ID'].isin(patients)] #even though it contained only one obs pr person, it still contained all patients, even those without notes in the days of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing csvs of the dfs\n",
    "df_uti.to_csv(\"data/preprocessed_data/df_uti.csv\")\n",
    "df_SFI.to_csv(\"data/preprocessed_data/df_SFI.csv\")\n",
    "df_admissions.to_csv(\"data/preprocessed_data/df_admissions.csv\")\n",
    "df_age.to_csv(\"data/preprocessed_data/df_age.csv\")\n",
    "df_female.to_csv(\"data/preprocessed_data/df_female.csv\")\n",
    "df_FIM_total.to_csv(\"data/preprocessed_data/df_FIM_total.csv\")\n",
    "df_acute_days.to_csv(\"data/preprocessed_data/df_acute_days.csv\")\n",
    "df_brain_injury.to_csv(\"data/preprocessed_data/df_brain_injury.csv\")\n",
    "df_outcome.to_csv(\"data/preprocessed_data/df_outcome.csv\")\n",
    "\n",
    "df_admissions_resampled.to_csv(\"data/preprocessed_data/df_admissions_resampled.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8f971b8dfd9a50933f9f90bf438ea60c1e2a4d59ca31e1c83263c2e44374f38"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('linapd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
