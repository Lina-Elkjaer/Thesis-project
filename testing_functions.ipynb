{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "df_female = pd.read_csv('test_data2/df_female.csv')\n",
    "df_age = pd.read_csv('test_data2/df_age.csv')\n",
    "df_SFI = pd.read_csv('test_data2/df_SFI.csv')\n",
    "df_uti = pd.read_csv('test_data2/df_uti.csv')\n",
    "df_admissions = pd.read_csv('test_data2/df_admissions.csv')\n",
    "df_FIM_total = pd.read_csv('test_data2/df_FIM_total.csv')\n",
    "df_acute_days = pd.read_csv('test_data2/df_acute_days.csv')\n",
    "df_brain_injury = pd.read_csv('test_data2/df_brain_injury_mod.csv')\n",
    "\n",
    "#Removing extra column\n",
    "df_female = df_female.loc[:, ~df_female.columns.str.contains('^Unnamed')]\n",
    "df_age = df_age.loc[:, ~df_age.columns.str.contains('^Unnamed')]\n",
    "df_SFI = df_SFI.loc[:, ~df_SFI.columns.str.contains('^Unnamed')]\n",
    "df_uti = df_uti.loc[:, ~df_uti.columns.str.contains('^Unnamed')]\n",
    "df_admissions = df_admissions.loc[:, ~df_admissions.columns.str.contains('^Unnamed')]\n",
    "df_FIM_total = df_FIM_total.loc[:, ~df_FIM_total.columns.str.contains('^Unnamed')]\n",
    "df_acute_days = df_acute_days.loc[:, ~df_acute_days.columns.str.contains('^Unnamed')]\n",
    "df_brain_injury = df_brain_injury.loc[:, ~df_brain_injury.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating uti df with negative cases as well\n",
    "merged = pd.merge(df_age, df_uti, on=['ID'], how='left')\n",
    "\n",
    "merged = merged[['ID','value']]\n",
    "\n",
    "#turning UVI-neg cases from nan to 0\n",
    "where_are_NaNs = np.isnan(merged)\n",
    "merged[where_are_NaNs] = 0\n",
    "\n",
    "#checking\n",
    "print(merged)\n",
    "\n",
    "#Changing from floats to int\n",
    "merged['value'] = merged['value'].astype('int')\n",
    "\n",
    "merged = pd.merge(merged, df_uti, on=['ID', 'value'], how='left')\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important to call predictors static, dynamic or text, otherwise they will be skipped because the function will not know how to handle them!\n",
    "#Make a disclaimer message if there is such a df in the predictor dict\n",
    "predictor_dict = {'df_SFI_text':df_SFI, 'df_age_static':df_age, 'df_female_static':df_female}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import data_split\n",
    "\n",
    "predictor_dict_train, predictor_dict_test, y_train_df, y_test_df, df_admissions_train, df_admissions_test = data_split(df_outcome = merged, predictor_dict = predictor_dict, df_admissions = df_admissions, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfidf import tf_idf\n",
    "\n",
    "df_tfidfvect_train, df_tfidfvect_test = tf_idf(predictor_dict_train[\"df_SFI_text\"], predictor_dict_test[\"df_SFI_text\"])\n",
    "\n",
    "# #BÃ¸r tal-tokens slettes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Might be a stupid question, but since I use a pretrained embeddings model, I guess I should treat the test and train data in the same way?\n",
    "\n",
    "#from sentence_embeddings import sentence_embeddings\n",
    "\n",
    "#df_sentence_train = sentence_embeddings(df_free_text = predictor_dict_train[\"df_SFI\"], transformer_model = 'encoder-large-v1')\n",
    "\n",
    "#df_sentence_test = sentence_embeddings(df_free_text = predictor_dict_test[\"df_SFI\"], transformer_model = 'encoder-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparing_specs import preparing_specs\n",
    "\n",
    "\n",
    "\n",
    "X_final_train_tfidf, y_final_train_tfidf =  preparing_specs(embeddings = df_tfidfvect_train,\n",
    "                                                predictor_dict = predictor_dict_train,\n",
    "                                                prediction_times = df_admissions_train, \n",
    "                                                outcome_df = y_train_df, \n",
    "                                                embedding_type =\"tfidf\",\n",
    "                                                lookbehind = 4, \n",
    "                                                lookahead = 3)\n",
    "\n",
    "\n",
    "# X_final_train_transf, y_final_train_transf=  preparing_specs(embeddings = df_sentence_train,\n",
    "#                                                 predictor_dict = predictor_dict_train,\n",
    "#                                                 prediction_times = df_admissions_train, \n",
    "#                                                 outcome_df = y_train_df, \n",
    "#                                                 embedding_type =\"transformer\",\n",
    "#                                                 lookbehind = 4, \n",
    "#                                                 lookahead = 3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8f971b8dfd9a50933f9f90bf438ea60c1e2a4d59ca31e1c83263c2e44374f38"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('linapd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
